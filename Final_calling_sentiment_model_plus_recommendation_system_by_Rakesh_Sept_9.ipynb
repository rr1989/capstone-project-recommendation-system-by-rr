{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final calling_sentiment_model_plus_recommendation_system by Rakesh Sept 9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMpZJgQCZCvLzv8OAaPoVyc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rr1989/capstone-project-recommendation-system-by-rr/blob/main/Final_calling_sentiment_model_plus_recommendation_system_by_Rakesh_Sept_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUPcu1sHwjW9"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def sentiment_result(product_name,Pickled_RFC_Model):\n",
        "  import pandas as pd\n",
        "  #product_name = \"Clorox Disinfecting Bathroom Cleaner\"\n",
        "\n",
        "\n",
        "\n",
        "  from sklearn.model_selection import cross_val_score\n",
        "  from scipy.sparse import hstack\n",
        "  from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "  Ebuss_df = pd.read_csv(\"sample30.csv\")\n",
        "  Ebuss_df_subset = Ebuss_df.dropna(subset=['reviews_text'])\n",
        "  review_text=Ebuss_df_subset['reviews_text']\n",
        "  #TF-IDF\n",
        "  word_vectorizer = TfidfVectorizer(\n",
        "  sublinear_tf=True,\n",
        "  strip_accents='unicode',\n",
        "  analyzer='word',\n",
        "  token_pattern=r'\\w{1,}',\n",
        "  stop_words='english',\n",
        "  ngram_range=(1, 1),\n",
        "  max_features=10000)\n",
        "  word_vectorizer.fit(review_text)\n",
        "  char_vectorizer = TfidfVectorizer(\n",
        "  sublinear_tf=True,\n",
        "  strip_accents='unicode',\n",
        "  analyzer='char',\n",
        "  stop_words='english',\n",
        "  ngram_range=(2, 6),\n",
        "  max_features=50000)\n",
        "  char_vectorizer.fit(review_text)\n",
        "\n",
        "  index= Ebuss_df[Ebuss_df['name']==product_name].index.tolist()\n",
        "\n",
        "  item_text = Ebuss_df.loc[index]['reviews_text']\n",
        "\n",
        "\n",
        "  train_word_features = word_vectorizer.transform(item_text)\n",
        "\n",
        "  train_char_features = char_vectorizer.transform(item_text)\n",
        "\n",
        "  item_features = hstack([train_char_features, train_word_features])\n",
        "\n",
        "  predicted_result = Pickled_RFC_Model.predict(item_features)\n",
        "\n",
        "  if predicted_result.mean() > 4:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "def recommendation_system(p_username):\n",
        "    import pandas as pd\n",
        "    # Load the Model back from file\n",
        "    from sklearn.externals import joblib\n",
        "    #Pkl_Filename = \"Pickle_RFC1_Model.pkl\"\n",
        "    Pkl_Filename = \"Pickle_XGB1_Model.pkl\"\n",
        "\n",
        "    Pickled_RFC_Model = joblib.load(Pkl_Filename)\n",
        "\n",
        "    #Pickled_RFC_Model\n",
        "\n",
        "    #recommendation system\n",
        "\n",
        "    # import libraties\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    ratings = pd.read_csv('sample30.csv' , encoding='latin-1')\n",
        "    #ratings.head()\n",
        "\n",
        "    ratings = ratings[[\"reviews_username\",\"name\",\"reviews_rating\"]]\n",
        "\n",
        "    # Test and Train split of the dataset.\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    train, test = train_test_split(ratings, test_size=0.30, random_state=31)\n",
        "\n",
        "    train = train.groupby(by=[\"reviews_username\",'name']).mean()\n",
        "\n",
        "    train.reset_index(level=0, inplace=True)\n",
        "    train.reset_index(level=0, inplace=True)\n",
        "\n",
        "    # Item Based Similarity\n",
        "    df_pivot = train.pivot(\n",
        "    index='reviews_username',\n",
        "    columns='name',\n",
        "    values='reviews_rating').T\n",
        "\n",
        "    #df_pivot.head()\n",
        "\n",
        "    mean = np.nanmean(df_pivot, axis=1)\n",
        "    df_subtracted = (df_pivot.T-mean).T\n",
        "\n",
        "    from sklearn.metrics.pairwise import pairwise_distances\n",
        "\n",
        "    # Item Similarity Matrix\n",
        "    item_correlation = 1 - pairwise_distances(df_subtracted.fillna(0), metric='cosine')\n",
        "    item_correlation[np.isnan(item_correlation)] = 0\n",
        "\n",
        "    item_correlation[item_correlation<0]=0\n",
        "\n",
        "    #prediction\n",
        "    item_predicted_ratings = np.dot((df_pivot.fillna(0).T),item_correlation)\n",
        "\n",
        "    # Copy the train dataset into dummy_train\n",
        "    dummy_train = train.copy()\n",
        "\n",
        "    # The products not rated by user is marked as 1 for prediction.\n",
        "    dummy_train['reviews_rating'] = dummy_train['reviews_rating'].apply(lambda x: 0 if x>=1 else 1)\n",
        "\n",
        "    # Convert the dummy train dataset into matrix format.\n",
        "    dummy_train = dummy_train.pivot(\n",
        "    index='reviews_username',\n",
        "    columns='name',\n",
        "    values='reviews_rating').fillna(1)\n",
        "\n",
        "    item_final_rating = np.multiply(item_predicted_ratings,dummy_train)\n",
        "\n",
        "    user_input = p_username\n",
        "\n",
        "    d = item_final_rating.loc[user_input].sort_values(ascending=False)#[0:5]\n",
        "\n",
        "\n",
        "    j = 0\n",
        "    k = 0\n",
        "    predicted_list = []\n",
        "    original_list = []\n",
        "    for i in d:\n",
        "        predicted_result = sentiment_result(d.index[j],Pickled_RFC_Model)\n",
        "        #print(d.index[j])\n",
        "        #print(predicted_result)\n",
        "        if predicted_result == 1:\n",
        "            #print(d.index[j] + ' : ' + str(i))\n",
        "            predicted_list.append(d.index[j])\n",
        "            k = k + 1\n",
        "            if k == 5:\n",
        "              break\n",
        "        original_list.append(d.index[j])\n",
        "        j = j + 1\n",
        "        #print(j)\n",
        "    return d,predicted_list,original_list\n",
        "        #return predicted_list\n",
        "\n",
        "        \n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW6QfwIvwm3r",
        "outputId": "aa208a6d-2416-4998-ef2b-acf0a07ef1a9"
      },
      "source": [
        "d,predicted_list,original_list = recommendation_system(\"06stidriver\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:520: UserWarning: The parameter 'stop_words' will not be used since 'analyzer' != 'word'\n",
            "  warnings.warn(\"The parameter 'stop_words' will not be used\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOTtmICbw3Cy",
        "outputId": "5884b2ae-b71d-4223-8e11-5de187696676"
      },
      "source": [
        "d"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "name\n",
              "Clorox Disinfecting Bathroom Cleaner                                              0.766556\n",
              "Newman's Own Organics Licorice Twist, Black 5oz                                   0.022144\n",
              "L'or233al Paris Elvive Extraordinary Clay Rebalancing Conditioner - 12.6 Fl Oz    0.019876\n",
              "Sea Gull Lighting Six Light Bath Sconce/vanity - Brushed Nickel                   0.019500\n",
              "Mrs. Meyer's174 Lemon Verbena Laundry Scent Booster - 18oz                        0.014756\n",
              "                                                                                    ...   \n",
              "Naturtint Nutrideep Multiplier Protective Cream                                   0.000000\n",
              "Nature's Path Flax Plus Maple Pecan Crunch Cereal                                 0.000000\n",
              "Nature's Path Chunky Chocolate Peanut Chewy Granola Bars                          0.000000\n",
              "Musselman Apple Sauce, Cinnamon, 48oz                                             0.000000\n",
              "0.6 Cu. Ft. Letter A4 Size Waterproof 30 Min. Fire File Chest                     0.000000\n",
              "Name: 06stidriver, Length: 252, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0XQKPFd1w5W",
        "outputId": "15bea52a-553a-4c82-cce1-ec467458ba44"
      },
      "source": [
        "predicted_list"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Clorox Disinfecting Bathroom Cleaner',\n",
              " \"Newman's Own Organics Licorice Twist, Black 5oz\",\n",
              " \"L'or233al Paris Elvive Extraordinary Clay Rebalancing Conditioner - 12.6 Fl Oz\",\n",
              " 'Sea Gull Lighting Six Light Bath Sconce/vanity - Brushed Nickel',\n",
              " \"Mrs. Meyer's174 Lemon Verbena Laundry Scent Booster - 18oz\",\n",
              " 'Queen Helene Cocoa Butter Solid',\n",
              " 'Dark Shadows (includes Digital Copy) (ultraviolet) (dvdvideo)',\n",
              " \"Stacy's Simply Naked Bagel Chips\",\n",
              " 'Planes: Fire Rescue (2 Discs) (includes Digital Copy) (blu-Ray/dvd)',\n",
              " 'Pendaflex174 Divide It Up File Folder, Multi Section, Letter, Assorted, 12/pack',\n",
              " 'Tresemme Kertatin Smooth Infusing Conditioning',\n",
              " 'Iman Second To None Stick Foundation, Clay 1',\n",
              " 'Vicks Vaporub, Regular, 3.53oz',\n",
              " 'All,bran Complete Wheat Flakes, 18 Oz.',\n",
              " 'Orajel Maximum Strength Toothache Pain Relief Liquid',\n",
              " 'The Honest Company Laundry Detergent',\n",
              " \"Meguiar's Deep Crystal Car Wash 64-Oz.\",\n",
              " 'The Script - No Sound Without Silence (cd)',\n",
              " 'Tostitos Simply Blue Corn Tortilla Chips',\n",
              " 'My Big Fat Greek Wedding 2 (blu-Ray + Dvd + Digital)']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEwMzPHR2ehQ",
        "outputId": "defceb07-436a-4624-fd55-15cfe9776f36"
      },
      "source": [
        "original_list"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Clorox Disinfecting Bathroom Cleaner',\n",
              " \"Newman's Own Organics Licorice Twist, Black 5oz\",\n",
              " \"L'or233al Paris Elvive Extraordinary Clay Rebalancing Conditioner - 12.6 Fl Oz\",\n",
              " 'Sea Gull Lighting Six Light Bath Sconce/vanity - Brushed Nickel',\n",
              " \"Mrs. Meyer's174 Lemon Verbena Laundry Scent Booster - 18oz\",\n",
              " 'Queen Helene Cocoa Butter Solid',\n",
              " 'Dark Shadows (includes Digital Copy) (ultraviolet) (dvdvideo)',\n",
              " \"Stacy's Simply Naked Bagel Chips\",\n",
              " 'Planes: Fire Rescue (2 Discs) (includes Digital Copy) (blu-Ray/dvd)',\n",
              " 'Pendaflex174 Divide It Up File Folder, Multi Section, Letter, Assorted, 12/pack',\n",
              " 'Tresemme Kertatin Smooth Infusing Conditioning',\n",
              " 'Iman Second To None Stick Foundation, Clay 1',\n",
              " 'Nexxus Exxtra Gel Style Creation Sculptor',\n",
              " 'Vicks Vaporub, Regular, 3.53oz',\n",
              " 'All,bran Complete Wheat Flakes, 18 Oz.',\n",
              " 'Orajel Maximum Strength Toothache Pain Relief Liquid',\n",
              " 'The Honest Company Laundry Detergent',\n",
              " \"Meguiar's Deep Crystal Car Wash 64-Oz.\",\n",
              " 'The Script - No Sound Without Silence (cd)',\n",
              " 'Tostitos Simply Blue Corn Tortilla Chips']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w0VfB7K2gz2"
      },
      "source": [
        "from sklearn.externals import joblib\n",
        "Pkl_Filename = \"Pickle_RFC_Model.pkl\"\n",
        "\n",
        "Pickled_RFC_Model = joblib.load(Pkl_Filename)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_RTMiZyWNj7",
        "outputId": "4c7adf68-6a59-4983-a7da-9c3141d23c02"
      },
      "source": [
        "Pickled_RFC_Model"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-_FJgaVfhW8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}